/home/thanasis/Desktop/PhD/NLP-DB/spatial llms/sparagi_rdf/SpaRAGraph/benchmark
Evaluating model: meta-llama-3.1-8b-instruct_fewshot0 (BINARY)
[94mPrecision: [0m0.94
[94mRecall: [0m0.98
[94mF1-score: [0m0.96

Evaluating model: meta-llama-3.1-8b-instruct_fewshot1 (BINARY)
[94mPrecision: [0m0.84
[94mRecall: [0m0.96
[94mF1-score: [0m0.90

Evaluating model: meta-llama-3.1-8b-instruct_fewshot3 (BINARY)
[94mPrecision: [0m0.84
[94mRecall: [0m0.95
[94mF1-score: [0m0.89

Evaluating model: mistral-7b-instruct-v0.1_fewshot0 (BINARY)
[94mPrecision: [0m0.93
[94mRecall: [0m0.99
[94mF1-score: [0m0.96

Evaluating model: mistral-7b-instruct-v0.1_fewshot1 (BINARY)
[94mPrecision: [0m0.92
[94mRecall: [0m0.94
[94mF1-score: [0m0.93

Evaluating model: mistral-7b-instruct-v0.1_fewshot3 (BINARY)
[94mPrecision: [0m0.91
[94mRecall: [0m0.94
[94mF1-score: [0m0.92

Evaluating model: qwen2.5-7b-instruct_fewshot0 (BINARY)
[94mPrecision: [0m1.00
[94mRecall: [0m0.97
[94mF1-score: [0m0.98

Evaluating model: qwen2.5-7b-instruct_fewshot1 (BINARY)
[94mPrecision: [0m0.99
[94mRecall: [0m0.96
[94mF1-score: [0m0.97

Evaluating model: qwen2.5-7b-instruct_fewshot3 (BINARY)
[94mPrecision: [0m1.00
[94mRecall: [0m0.91
[94mF1-score: [0m0.95

Evaluating model: meta-llama-3.1-8b-instruct_fewshot0 (MULTICLASS)

[94mmacro-Precision: [0m0.74
[94mmacro-Recall: [0m0.71
[94mmacro-F1-score: [0m0.71

Evaluating model: meta-llama-3.1-8b-instruct_fewshot1 (MULTICLASS)

[94mmacro-Precision: [0m0.84
[94mmacro-Recall: [0m0.85
[94mmacro-F1-score: [0m0.83

Evaluating model: meta-llama-3.1-8b-instruct_fewshot3 (MULTICLASS)

[94mmacro-Precision: [0m0.83
[94mmacro-Recall: [0m0.84
[94mmacro-F1-score: [0m0.83

Evaluating model: mistral-7b-instruct-v0.1_fewshot0 (MULTICLASS)
[91mWarning: Invalid responses detected[0m
Invalid predicted values: ['no response']

[94mmacro-Precision: [0m0.59
[94mmacro-Recall: [0m0.35
[94mmacro-F1-score: [0m0.32

Evaluating model: mistral-7b-instruct-v0.1_fewshot1 (MULTICLASS)

[94mmacro-Precision: [0m0.82
[94mmacro-Recall: [0m0.81
[94mmacro-F1-score: [0m0.76

Evaluating model: mistral-7b-instruct-v0.1_fewshot3 (MULTICLASS)
[91mWarning: Invalid responses detected[0m
Invalid predicted values: ['no response']

[94mmacro-Precision: [0m0.88
[94mmacro-Recall: [0m0.87
[94mmacro-F1-score: [0m0.87

Evaluating model: qwen2.5-7b-instruct_fewshot0 (MULTICLASS)

[94mmacro-Precision: [0m0.83
[94mmacro-Recall: [0m0.82
[94mmacro-F1-score: [0m0.76

Evaluating model: qwen2.5-7b-instruct_fewshot1 (MULTICLASS)

[94mmacro-Precision: [0m0.86
[94mmacro-Recall: [0m0.85
[94mmacro-F1-score: [0m0.81

Evaluating model: qwen2.5-7b-instruct_fewshot3 (MULTICLASS)

[94mmacro-Precision: [0m0.88
[94mmacro-Recall: [0m0.87
[94mmacro-F1-score: [0m0.84

Evaluating model: meta-llama-3.1-8b-instruct_fewshot0 (MULTILABEL)
[94msample-average Precision: [0m0.44
[94msample-average Recall: [0m0.68
[94msample-average F1-score: [0m0.51

Evaluating model: meta-llama-3.1-8b-instruct_fewshot1 (MULTILABEL)
[94msample-average Precision: [0m0.61
[94msample-average Recall: [0m0.65
[94msample-average F1-score: [0m0.62

Evaluating model: meta-llama-3.1-8b-instruct_fewshot3 (MULTILABEL)
[94msample-average Precision: [0m0.60
[94msample-average Recall: [0m0.61
[94msample-average F1-score: [0m0.60

Evaluating model: mistral-7b-instruct-v0.1_fewshot0 (MULTILABEL)
[94msample-average Precision: [0m0.30
[94msample-average Recall: [0m0.58
[94msample-average F1-score: [0m0.37

Evaluating model: mistral-7b-instruct-v0.1_fewshot1 (MULTILABEL)
[94msample-average Precision: [0m0.46
[94msample-average Recall: [0m0.63
[94msample-average F1-score: [0m0.50

Evaluating model: mistral-7b-instruct-v0.1_fewshot3 (MULTILABEL)
[94msample-average Precision: [0m0.42
[94msample-average Recall: [0m0.57
[94msample-average F1-score: [0m0.46

Evaluating model: qwen2.5-7b-instruct_fewshot0 (MULTILABEL)
[94msample-average Precision: [0m0.72
[94msample-average Recall: [0m0.85
[94msample-average F1-score: [0m0.76

Evaluating model: qwen2.5-7b-instruct_fewshot1 (MULTILABEL)
[94msample-average Precision: [0m0.74
[94msample-average Recall: [0m0.81
[94msample-average F1-score: [0m0.76

Evaluating model: qwen2.5-7b-instruct_fewshot3 (MULTILABEL)
[94msample-average Precision: [0m0.72
[94msample-average Recall: [0m0.77
[94msample-average F1-score: [0m0.73

All evaluations completed!
